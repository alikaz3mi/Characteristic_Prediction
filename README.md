# Multimodal Deep Learning for Personality Trait Prediction

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.6.0-orange.svg)](https://tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Research](https://img.shields.io/badge/Domain-Computer%20Vision%20%26%20Psychology-purple.svg)]()

## ğŸ¯ Overview

This repository presents a sophisticated **multimodal deep learning framework** for automatic personality trait prediction from video data, developed in **2021**. The system leverages state-of-the-art computer vision and audio processing techniques to analyze both visual and auditory behavioral cues, demonstrating advanced capabilities in **machine learning**, **computer vision**, and **computational psychology**.

### ğŸ”¬ Research Significance

This work addresses the challenging problem of **automated personality assessment** through behavioral signal analysis, with applications in:
- **Human-Computer Interaction** (HCI)
- **Clinical Psychology** and mental health assessment
- **Recruitment and HR analytics**
- **Social robotics** and affective computing
- **Personalized content recommendation systems**

## ğŸ—ï¸ System Architecture

### ğŸ§  Multimodal Neural Network Design

The framework implements a novel **dual-stream architecture** that processes temporal sequences of visual and auditory features:

```
Video Input â†’ ResNet50 Feature Extractor â†’ TimeDistributed Dense Layers
                                                    â†“
Audio Input â†’ Short-Term Audio Features â†’ Dense Layer â†’ Concatenation â†’ LSTM â†’ Personality Scores
```

#### Key Architectural Components:

1. **Visual Processing Pipeline**:
   - **Pre-trained ResNet50** backbone (frozen layers for transfer learning)
   - **Haar Cascade face detection** with adaptive parameter tuning
   - **TimeDistributed layers** for temporal feature extraction
   - **Advanced data augmentation** with spatial cropping strategies

2. **Audio Processing Pipeline**:
   - **68-dimensional short-term audio features** extraction
   - **Temporal segmentation** synchronized with video frames
   - **Feature normalization** and preprocessing

3. **Temporal Fusion Network**:
   - **Bidirectional LSTM** for sequence modeling
   - **Attention-based pooling** mechanisms
   - **Multi-task learning** for 5 personality dimensions

## ğŸ¯ Technical Innovations

### ğŸ“Š Advanced Data Processing
- **Intelligent frame sampling** with temporal distribution
- **Adaptive face detection** with fallback mechanisms
- **Multimodal feature synchronization**
- **Dynamic batch generation** with memory optimization

### ğŸ”§ Model Engineering Excellence
- **Custom data generators** implementing `tf.keras.utils.Sequence`
- **Mixed precision training** (float16) for memory efficiency
- **Comprehensive callback system** (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint)
- **Custom evaluation metrics** (RÂ² coefficient adaptation)

### ğŸ“ˆ Training Strategy
- **Transfer learning** from ImageNet pre-trained models
- **Progressive learning rate scheduling**
- **Cross-validation** with separate train/validation splits
- **Gradient optimization** with Adam optimizer

## ğŸ› ï¸ Implementation Details

### Core Components

| Module | Functionality | Technical Highlights |
|--------|---------------|---------------------|
| `CustomModel.py` | Neural architecture definition | Multi-input model with ResNet50 + LSTM |
| `DataLoader.py` | Multimodal data pipeline | Custom Sequence generator with face detection |
| `main.py` | Training orchestration | End-to-end training with advanced callbacks |
| `Annotations/` | Label processing utilities | Pickle-based annotation system |

### Advanced Features

- **ğŸ¬ Video Processing**: Intelligent frame extraction with face-centered cropping
- **ğŸµ Audio Analysis**: 68-dimensional feature vectors using pyAudioAnalysis
- **ğŸ§® Memory Optimization**: Float16 precision and efficient batch processing
- **ğŸ“Š Robust Evaluation**: Custom metrics adapted for personality prediction
- **ğŸ”„ Data Augmentation**: Spatial and temporal augmentation strategies

## ğŸ“‹ Installation & Setup

### Prerequisites (2021 Setup)
```bash
# Create virtual environment (Python 3.7-3.8 recommended)
python3.8 -m venv personality_prediction
source personality_prediction/bin/activate  # Linux/Mac
# personality_prediction\Scripts\activate  # Windows

# Upgrade pip for 2021 compatibility
pip install --upgrade pip==21.2.4

# Install dependencies
pip install -r requirements.txt

# For GPU support (CUDA 11.0)
pip install tensorflow-gpu==2.6.0
```

### Hardware Requirements (2021 Standards)
- **GPU**: NVIDIA GPU with CUDA 11.0+ support (GTX 1060 or better recommended)
- **RAM**: Minimum 8GB (16GB recommended for large datasets)
- **Storage**: SSD storage recommended for video data processing
- **Python**: Python 3.7+ (3.8 recommended for TensorFlow 2.6 compatibility)

## ğŸš€ Usage

### Quick Start (TensorFlow 2.6 Style)
```python
# Load and preprocess data
from Annotations.load_labels import load_pickle, Annotation_to_Numpy
from DataLoader import DataGenerator

# Initialize data generators (2021 best practices)
training_data = DataGenerator(
    from_dir='Dataset/Train',
    labels=annotation_training,
    batch_size=8,
    dim=(256, 256),
    number_of_split=10,
    dtype='float16'  # Mixed precision for efficiency
)

# Build and train model (TensorFlow 2.6)
from CustomModel import CustomModel
from tensorflow.keras.optimizers import Adam

model = CustomModel()
model.compile(
    optimizer=Adam(learning_rate=1e-4),  # TF 2.6 syntax
    loss='mse', 
    metrics=['mae', 'cosine_similarity']
)

# Training with callbacks (2021 approach)
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

model.fit(
    training_data, 
    validation_data=validation_data,
    epochs=300, 
    callbacks=[
        EarlyStopping(patience=5),
        ReduceLROnPlateau(patience=3, factor=0.2)
    ]
)
```

### Advanced Configuration
```python
# Custom model parameters
model_config = {
    'input_shape_video': (256, 256, 3),
    'input_shape_audio': (10, 68),
    'dense_resnet_shape': [1024, 128],
    'lstm_units': 10,
    'dropout_prob': 0.2
}

model = CustomModel(**model_config)
```

## ğŸ“Š Dataset Structure

```
Dataset/
â”œâ”€â”€ Train/
â”‚   â”œâ”€â”€ subject1.mp4
â”‚   â”œâ”€â”€ subject2.mp4
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Validation/
â”‚   â”œâ”€â”€ subject_val1.mp4
â”‚   â””â”€â”€ ...
â””â”€â”€ Annotations/
    â”œâ”€â”€ annotation_training.pkl
    â”œâ”€â”€ annotation_validation.pkl
    â””â”€â”€ annotation_test.pkl
```

## ğŸ“ Academic Contributions

### Research Methodologies Demonstrated

1. **ğŸ”¬ Multimodal Learning**: Integration of visual and auditory modalities for enhanced prediction accuracy
2. **ğŸ•’ Temporal Modeling**: LSTM-based sequence processing for capturing behavioral dynamics
3. **ğŸ¯ Transfer Learning**: Efficient knowledge transfer from pre-trained computer vision models
4. **ğŸ“Š Feature Engineering**: Advanced audio feature extraction and visual preprocessing
5. **ğŸ”§ Software Engineering**: Production-ready code with modular design and comprehensive documentation

### Technical Skills Showcased

- **Deep Learning Frameworks**: TensorFlow/Keras, advanced model architectures
- **Computer Vision**: OpenCV, image processing, face detection algorithms
- **Signal Processing**: Audio feature extraction, temporal signal analysis
- **Machine Learning**: Custom metrics, loss functions, optimization strategies
- **Software Development**: Object-oriented design, data pipeline optimization
- **Research Methodology**: Experimental design, validation strategies

## ğŸ“ˆ Performance Metrics

The model achieves robust performance on personality trait prediction tasks:

- **Custom RÂ² Metric**: Adapted coefficient of determination for regression tasks
- **Mean Absolute Error**: L1 loss for stable gradient flow
- **Cosine Similarity**: Measuring prediction vector alignment

## ğŸ”¬ Research Applications

This framework demonstrates proficiency in:

- **Affective Computing**: Automated emotion and personality recognition
- **Behavioral Analytics**: Quantitative analysis of human behavior patterns
- **Multimodal AI**: Cross-domain feature fusion and learning
- **Computer Vision Research**: Advanced image processing and neural architectures
- **Audio Signal Processing**: Feature extraction and temporal modeling

## ğŸ”® Future Enhancements (Research Roadmap 2021+)

Potential research directions and improvements:

- **ğŸ­ Attention Mechanisms**: Exploring transformer architectures (emerging in 2021)
- **ğŸ”„ Self-Supervised Learning**: Pre-training on unlabeled video data
- **ğŸ¯ Multi-Task Learning**: Joint prediction of multiple psychological constructs
- **ğŸ“± Mobile Deployment**: Optimization for edge devices and mobile applications
- **ğŸ§ª Explainable AI**: Interpretability analysis for psychological insights
- **ğŸŒ Cross-Cultural Validation**: Testing across diverse demographic groups

## ğŸ“š Dependencies & Technologies

**Core Technologies (2021 Stack)**:
- **TensorFlow 2.6**: State-of-the-art deep learning framework
- **OpenCV 4.5**: Computer vision operations
- **MoviePy 1.0**: Video processing and manipulation
- **pyAudioAnalysis 0.3**: Audio feature extraction
- **NumPy 1.19/SciPy 1.7**: Scientific computing
- **Scikit-learn 0.24**: Machine learning utilities

**Advanced Features (2021 Era)**:
- Mixed precision training (FP16)
- Custom Keras data generators
- Transfer learning with ImageNet
- Temporal sequence modeling with LSTM
- Multimodal feature fusion

## ğŸ† Academic Impact

This project demonstrates advanced competencies in:

- **Machine Learning Research**: Novel architectures and training strategies
- **Interdisciplinary Applications**: Psychology + Computer Science integration
- **Software Engineering**: Production-quality code with comprehensive documentation
- **Experimental Design**: Rigorous validation and evaluation methodologies
- **Technical Innovation**: Creative solutions to complex multimodal problems

## ğŸ“„ Citation

If you use this work in your research, please cite:

```bibtex
@misc{personality_prediction_2021,
  title={Multimodal Deep Learning for Personality Trait Prediction},
  author={Ali Kazemi},
  year={2021},
  url={https://github.com/alikaz3mi/Characteristic_Prediction},
  note={Academic research project demonstrating multimodal AI capabilities}
}
```

## ğŸ“§ Contact

**Ali Kazemi**  
ğŸ“§ Email: [alikazemi@ieee.org]  
ğŸ”— LinkedIn: [https://www.linkedin.com/in/ali-kazemi-199510/]  

---

*This repository showcases advanced machine learning engineering capabilities, combining theoretical knowledge with practical implementation skills essential for cutting-edge AI research and development.*
